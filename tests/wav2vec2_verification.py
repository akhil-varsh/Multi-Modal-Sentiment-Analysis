#!/usr/bin/env python3
"""
Final Wav2Vec2 Implementation Verification
Comprehensive test to ensure all components work together
"""

import sys
from pathlib import Path
import torch
import os
import tempfile
import numpy as np

# Add src to path
sys.path.append(str(Path(__file__).parent.parent / 'src'))

def test_component_1_feature_extraction():
    """Test 1: Wav2Vec2 feature extraction"""
    print("üß™ Test 1: Wav2Vec2 Feature Extraction")
    print("-" * 40)
    
    try:
        from feature_extractors import AudioSentimentModel
        
        # Initialize model
        audio_model = AudioSentimentModel()
        
        # Check Wav2Vec2 availability
        if not (hasattr(audio_model, 'use_wav2vec2') and audio_model.use_wav2vec2):
            print("‚ùå Wav2Vec2 not available")
            return False
        
        print("‚úÖ Wav2Vec2 model loaded successfully")
        
        # Create dummy audio for testing
        import wave
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            # Generate test audio
            sample_rate = 16000
            duration = 2
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            audio_data = np.sin(2 * np.pi * 440 * t)
            
            # Write WAV file
            with wave.open(tmp_file.name, 'w') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(sample_rate)
                wav_file.writeframes((audio_data * 32767).astype(np.int16).tobytes())
            
            # Test feature extraction
            features = audio_model.extract_features_from_audio(tmp_file.name)
            
            # Clean up
            os.unlink(tmp_file.name)
        
        # Verify features
        if features.shape != torch.Size([768]):
            print(f"‚ùå Feature shape mismatch: expected [768], got {features.shape}")
            return False
        
        print(f"‚úÖ Feature extraction successful: shape={features.shape}")
        return True
        
    except Exception as e:
        print(f"‚ùå Test 1 failed: {e}")
        return False

def test_component_2_sentiment_prediction():
    """Test 2: Audio sentiment prediction"""
    print("\nüß™ Test 2: Audio Sentiment Prediction")
    print("-" * 40)
    
    try:
        from feature_extractors import AudioSentimentModel
        
        # Initialize model
        audio_model = AudioSentimentModel()
        
        # Create dummy features
        dummy_features = torch.randn(1, 768)
        
        # Test prediction
        output = audio_model(dummy_features)
        
        # Verify output
        if output.shape != torch.Size([1, 3]):
            print(f"‚ùå Output shape mismatch: expected [1, 3], got {output.shape}")
            return False
        
        # Test probabilities
        probabilities = torch.softmax(output, dim=-1)
        predicted_class = torch.argmax(probabilities, dim=-1)
        
        print(f"‚úÖ Sentiment prediction successful")
        print(f"   Predicted class: {predicted_class.item()}")
        print(f"   Probabilities: {probabilities.squeeze().tolist()}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test 2 failed: {e}")
        return False

def test_component_3_streamlit_integration():
    """Test 3: Streamlit app integration"""
    print("\nüß™ Test 3: Streamlit App Integration")
    print("-" * 40)
    
    try:
        # Test import of streamlit app components
        sys.path.append(str(Path(__file__).parent.parent / 'app'))
        
        # This will test if the imports work correctly
        import importlib.util
        
        streamlit_path = Path(__file__).parent.parent / 'app' / 'streamlit_app.py'
        spec = importlib.util.spec_from_file_location("streamlit_app", streamlit_path)
        
        if spec is None:
            print("‚ùå Could not load streamlit app module")
            return False
        
        print("‚úÖ Streamlit app module can be loaded")
        print("   Note: Full streamlit test requires 'streamlit run app/streamlit_app.py'")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test 3 failed: {e}")
        return False

def test_component_4_cli_integration():
    """Test 4: CLI interface integration"""
    print("\nüß™ Test 4: CLI Interface Integration")
    print("-" * 40)
    
    try:
        # Test import of CLI components
        sys.path.append(str(Path(__file__).parent.parent / 'app'))
        
        import importlib.util
        
        cli_path = Path(__file__).parent.parent / 'app' / 'enhanced_predict.py'
        spec = importlib.util.spec_from_file_location("enhanced_predict", cli_path)
        
        if spec is None:
            print("‚ùå Could not load CLI module")
            return False
        
        print("‚úÖ CLI interface module can be loaded")
        print("   Note: Full CLI test requires 'python app/enhanced_predict.py --interactive'")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test 4 failed: {e}")
        return False

def test_component_5_real_audio_processing():
    """Test 5: Real audio file processing"""
    print("\nüß™ Test 5: Real Audio File Processing")
    print("-" * 40)
    
    try:
        from feature_extractors import AudioSentimentModel
        
        # Look for real audio files
        audio_dir = Path(__file__).parent.parent / 'data' / 'audio_emotion' / 'emodb' / 'wav'
        
        if not audio_dir.exists():
            print("‚ö†Ô∏è Real audio files not found (EMO-DB dataset)")
            print("   Run 'python scripts/download_datasets.py' to download")
            return True  # Not a failure, just missing data
        
        audio_files = list(audio_dir.glob('*.wav'))[:3]
        
        if not audio_files:
            print("‚ö†Ô∏è No audio files found in data directory")
            return True
        
        # Initialize model
        audio_model = AudioSentimentModel()
        
        if not (hasattr(audio_model, 'use_wav2vec2') and audio_model.use_wav2vec2):
            print("‚ùå Wav2Vec2 not available for real audio test")
            return False
        
        print(f"üìÅ Testing with {len(audio_files)} real audio files...")
        
        for audio_file in audio_files:
            try:
                # Process real audio file
                features = audio_model.extract_features_from_audio(str(audio_file))
                output = audio_model(features.unsqueeze(0))
                probabilities = torch.softmax(output, dim=-1)
                predicted_class = torch.argmax(probabilities, dim=-1)
                
                print(f"   ‚úÖ {audio_file.name}: Class {predicted_class.item()}")
                
            except Exception as e:
                print(f"   ‚ùå {audio_file.name}: {e}")
                return False
        
        print("‚úÖ Real audio processing successful")
        return True
        
    except Exception as e:
        print(f"‚ùå Test 5 failed: {e}")
        return False

def main():
    """Run all verification tests"""
    print("üöÄ Wav2Vec2 Implementation Verification Suite")
    print("=" * 60)
    
    # Check if running from correct directory
    if not Path('src/feature_extractors.py').exists():
        print("‚ùå Please run this script from the project root directory:")
        print("   cd 'c:\\Users\\Akhil\\Python_Projects\\ML\\Multi Modal-Sentiment Analysis'")
        print("   python tests/wav2vec2_verification.py")
        return
    
    tests = [
        test_component_1_feature_extraction,
        test_component_2_sentiment_prediction,
        test_component_3_streamlit_integration,
        test_component_4_cli_integration,
        test_component_5_real_audio_processing
    ]
    
    results = []
    
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"‚ùå Unexpected error in {test.__name__}: {e}")
            results.append(False)
    
    # Summary
    print("\n" + "=" * 60)
    print("üìä Verification Summary:")
    
    test_names = [
        "Wav2Vec2 Feature Extraction",
        "Audio Sentiment Prediction", 
        "Streamlit App Integration",
        "CLI Interface Integration",
        "Real Audio File Processing"
    ]
    
    passed = 0
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"   {i+1}. {name:<30} {status}")
        if result:
            passed += 1
    
    print(f"\nüéØ Results: {passed}/{len(tests)} tests passed")
    
    if passed == len(tests):
        print("\nüéâ All tests passed! Wav2Vec2 implementation is ready!")
        print("\nüöÄ You can now:")
        print("   ‚Ä¢ Run Streamlit app: streamlit run app/streamlit_app.py")
        print("   ‚Ä¢ Use CLI interface: python app/enhanced_predict.py --interactive")
        print("   ‚Ä¢ Train models: python training/train_multimodal_real.py")
    else:
        print(f"\n‚ö†Ô∏è {len(tests) - passed} test(s) failed. Please check the errors above.")
    
    return passed == len(tests)

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

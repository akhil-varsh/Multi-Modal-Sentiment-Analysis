# üõ†Ô∏è Custom Dataset Guide

This guide explains how to prepare your own data for the Multi-Modal Sentiment Analysis system.

---

## üìÇ Option 1: Metadata File (Recommended)

This is the most standard approach. You create a CSV file that lists the paths to your text, audio, and image files.

### 1. Folder Structure
Organize your raw files however you like:
```
data/
‚îú‚îÄ‚îÄ train.csv
‚îú‚îÄ‚îÄ val.csv
‚îú‚îÄ‚îÄ my_audio/
‚îÇ   ‚îú‚îÄ‚îÄ sample1.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ my_images/
‚îÇ   ‚îú‚îÄ‚îÄ face1.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

### 2. CSV Format
Create a `train.csv` (and `val.csv`) in the `data/` folder with these columns:
- `text`: The text content.
- `audio_path`: Relative path to the audio file.
- `image_path`: Relative path to the image file.
- `label`: Integer representing sentiment (**0: Negative, 1: Neutral, 2: Positive**).

**Example `train.csv`:**
```csv
text,audio_path,image_path,label
"I am so happy today!",my_audio/sample1.wav,my_images/face1.jpg,2
"This is very disappointing.",my_audio/sad.wav,my_images/face2.jpg,0
"I am waiting for the bus.",my_audio/ambient.wav,my_images/street.jpg,1
```

---

## üìÅ Option 2: Folder-Based Structure (Quick Setup)

If you don't want to create a CSV, the system can automatically pair files based on their **filenames**.

### 1. Folder Structure
Place your files in these exact subdirectories under `data/`:
```
data/
‚îú‚îÄ‚îÄ text_sentiment/
‚îÇ   ‚îú‚îÄ‚îÄ sample_01.txt
‚îÇ   ‚îî‚îÄ‚îÄ sample_02.txt
‚îú‚îÄ‚îÄ audio_emotion/
‚îÇ   ‚îú‚îÄ‚îÄ sample_01.wav
‚îÇ   ‚îî‚îÄ‚îÄ sample_02.wav
‚îú‚îÄ‚îÄ image_emotion/
‚îÇ   ‚îú‚îÄ‚îÄ sample_01.jpg
‚îÇ   ‚îî‚îÄ‚îÄ sample_02.png
```

### 2. How it works
The system scans `text_sentiment/` first. For every `.txt` file (e.g., `sample_01.txt`), it looks for a file with the **same name** in the audio and image folders (e.g., `sample_01.wav` and `sample_01.jpg`).

> [!NOTE]
> Labels for this method default to **1 (Neutral)**. Use Option 1 if you need specific labels for training.

---

## üìè Technical Requirements

To get the best results, ensure your data meets these specs:

| Modality | Requirement |
|----------|-------------|
| **Text** | Clean UTF-8 encoded plain text. |
| **Audio** | **16kHz sampling rate** mono (WAV or MP3). System will resample if needed. |
| **Image**| RGB format (JPG/PNG). System will resize to 224x224. |
| **Labels**| **0**: Negative \| **1**: Neutral \| **2**: Positive |

---

## üöÄ How to Use Your Dataset

1.  **Clear existing data**: Delete any temporary dummy files in `data/`.
2.  **Add your files**: Use one of the options above.
3.  **Run Training**:
    ```bash
    python train.py
    ```
    The script will automatically detect your local files and start training.

4.  **Verify**: Keep an eye on the console logs. It will report how many samples were found.
    ```
    Scanning data for samples...
    - Training samples: 500
    - Validation samples: 50
    ```

---

## üé® Visualization
Once trained, launch the app:
```bash
streamlit run app.py
```
Upload your own files in the app to see how the model generalizes to your custom data!
